{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED TEXT MINING\n",
    "- 본 자료는 텍스트 마이닝을 활용한 연구 및 강의를 위한 목적으로 제작되었습니다.\n",
    "- 본 자료를 강의 목적으로 활용하고자 하시는 경우 꼭 아래 메일주소로 연락주세요.\n",
    "- 본 자료에 대한 허가되지 않은 배포를 금지합니다.\n",
    "- 강의, 저작권, 출판, 특허, 공동저자에 관련해서는 문의 바랍니다.\n",
    "- **Contact : ADMIN(admin@teanaps.com)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## WEEK 03-2. 정적 페이지 수집하기: 실시간 검색어, 영화댓글\n",
    "- Python을 활용해 단순한 웹페이지에서 데이터를 크롤링하는 방법에 대해 다룹니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **\\*\\*\\* 주의사항 \\*\\*\\***  \n",
    "본 자료에서 설명하는 웹크롤링하는 방법은 해당 기법에 대한 이해를 돕고자하는 교육의 목적으로 사용되었으며,  \n",
    "이를 활용한 대량의 무단 크롤링은 범죄에 해당할 수 있음을 알려드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 01. 네이버 영화댓글을 대량으로 가져오기\n",
    "> - 본 자료를 응용하여 네이버 영화댓글을 부가정보와 함께 대량으로 가져오는 코드를 작성합니다.\n",
    "> - 영화댓글 페이지의 100페이지 분량의 댓글을 수집합니다.\n",
    "> - 영화댓글 텍스트와 함께, 작성일자와 평점을 같이 가져옵니다.\n",
    "> - 영화댓글, 작성일자, 평점을 탭(\\t) 단위로 구분하여 파일에 저장합니다.  \n",
    "\n",
    "> HINT. 영화댓글 URL 맨 뒤의 숫자는 페이지 번호를 의미합니다. (\"&page=1\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\r"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "\n",
    "PAGE_LIMIT = 10\n",
    "URL = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=167491&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\"\n",
    "SAVE_FILE_PATH = \"movie_comment.txt\"\n",
    "\n",
    "f = open(SAVE_FILE_PATH, \"w\", encoding=\"utf-8\")\n",
    "for page in range(1, PAGE_LIMIT+1):\n",
    "    print(page, end=\"\\r\")\n",
    "    URL = URL + str(page)\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    comment_list = soup.findAll(\"div\", {'class': \"score_reple\",})\n",
    "    for comment in comment_list:\n",
    "        span_tag_list = comment.find(\"p\").findAll(\"span\")\n",
    "        if span_tag_list[0].text == \"관람객\":\n",
    "            #print(span_tag_list[1].text.strip())\n",
    "            f.write(span_tag_list[1].text.strip() + \"\\n\")\n",
    "        else:\n",
    "            #print(span_tag_list[0].text.strip())\n",
    "            f.write(span_tag_list[0].text.strip() + \"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
